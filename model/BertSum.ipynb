{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 16:58:49.606134  8320 file_utils.py:39] PyTorch version 1.2.0 available.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import warnings\n",
    "import logging\n",
    "import joblib\n",
    "import requests\n",
    "import pysentiment as ps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from summarizer import Summarizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_content(url, ratio=0.8):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        res_origin: complete paragraph string\n",
    "        res_ps: important sentence string\n",
    "        res_bertsum: filtered string by BertSum\n",
    "    \"\"\"\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    paragraph = soup.find_all('p')\n",
    "    paragraph = [p.text for p in paragraph]\n",
    "    paragraph = paragraph[1:-1]\n",
    "    res_origin = \"\".join(paragraph)\n",
    "    hiv4_function = ps.hiv4.HIV4()\n",
    "    po = []\n",
    "    for p in paragraph:\n",
    "        tokens = hiv4_function.tokenize(p)\n",
    "        s = hiv4_function.get_score(tokens)\n",
    "        po.append(s['Polarity'])\n",
    "    res = []\n",
    "    for i, p in enumerate(po):\n",
    "        if(float(p) >= 0.85 or float(p) <= -0.85):\n",
    "            res.append(paragraph[i])\n",
    "    res_ps = \"\".join(res)\n",
    "    bert_summarizer = Summarizer()\n",
    "    result = bert_summarizer(res_origin, ratio=ratio)\n",
    "    res_bertsum = ''.join(result)\n",
    "    return (res_origin, res_ps, res_bertsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c677da22df47f6be4d1989b56dab24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 16:59:02.322458  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 16:59:02.323458  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 16:59:02.774490  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 16:59:15.594702  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 16:59:18.995673  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 16:59:18.997671  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 16:59:19.053703  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 16:59:27.675673  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 16:59:31.139706  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 16:59:31.140673  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 16:59:31.207706  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 16:59:39.766703  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 16:59:43.772668  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 16:59:43.773643  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 16:59:43.839672  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 16:59:52.346713  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 16:59:57.046690  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 16:59:57.047683  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 16:59:57.138715  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 17:00:05.924759  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 17:00:10.623778  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 17:00:10.624749  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0728 17:00:10.688786  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 17:00:19.303278  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 17:00:24.517315  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 17:00:24.518277  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 17:00:24.588313  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 17:00:34.235280  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 17:00:39.303310  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 17:00:39.304279  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 17:00:39.389310  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 17:00:48.690278  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 17:00:53.009276  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 17:00:53.011305  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 17:00:53.066316  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 17:01:02.508307  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 17:01:08.314277  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 17:01:08.316277  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 17:01:08.759285  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 17:01:17.778307  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0728 17:01:22.350307  8320 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
      "I0728 17:01:22.351277  8320 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0728 17:01:22.409278  8320 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\73e65a4648c1a5eab31ecea94e04a92a7168cd7089d588b68e5bc057aff40421.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0728 17:01:31.636279  8320 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = joblib.load(\"../data/sp500_top100_v1.bin\")\n",
    "df = df.iloc[0:10, :]\n",
    "\n",
    "tqdm.pandas()\n",
    "df[[\"content\", \"ps_content\", \"bs_content\"]] = df.progress_apply(lambda row: pd.Series(add_content(row[\"url\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>url</th>\n",
       "      <th>ticker</th>\n",
       "      <th>content</th>\n",
       "      <th>ps_content</th>\n",
       "      <th>bs_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRIEF-Apple Inc Says Not Allowing Entertainmen...</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSFWN2B61K2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>March 14 (Reuters) - Apple Inc: * APPLE INC SA...</td>\n",
       "      <td>* APPLE INC SAYS NOT ALLOWING ENTERTAINMENT OR...</td>\n",
       "      <td>March 14 (Reuters) - Apple Inc: * APPLE INC SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple signs multi-year deals with major music ...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSKBN20Z33J</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>(Reuters) - Apple Inc has sealed multi-year li...</td>\n",
       "      <td>(Reuters) - Apple Inc has sealed multi-year li...</td>\n",
       "      <td>(Reuters) - Apple Inc has sealed multi-year li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple signs multi-year deals with major music ...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSL4N2B54T2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>(Reuters) - Apple Inc has sealed multi-year li...</td>\n",
       "      <td>(Reuters) - Apple Inc has sealed multi-year li...</td>\n",
       "      <td>(Reuters) - Apple Inc has sealed multi-year li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chinese regulators remove 'Plague Inc' game fr...</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSKCN20M043</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>BEIJING/SHANGHAI (Reuters) - The video game “P...</td>\n",
       "      <td>The regulator did not respond to Reuters phone...</td>\n",
       "      <td>BEIJING/SHANGHAI (Reuters) - The video game “P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UPDATE 1-Chinese regulators remove 'Plague Inc...</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSL3N2AS0OO</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>BEIJING/SHANGHAI (Reuters) - The video game “P...</td>\n",
       "      <td>The regulator did not respond to Reuters phone...</td>\n",
       "      <td>BEIJING/SHANGHAI (Reuters) - The video game “P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apple launches new MacBook Pro</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSL4N2CM29Z</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>May 4 (Reuters) - Apple Inc on Monday launched...</td>\n",
       "      <td>Apple said here its new lineup of MacBook Pro ...</td>\n",
       "      <td>May 4 (Reuters) - Apple Inc on Monday launched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Broadcom to supply wireless components to Apple</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSKBN1ZM32H</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>(Reuters) - Chipmaker Broadcom Inc (AVGO.O) sa...</td>\n",
       "      <td>(Reuters) - Chipmaker Broadcom Inc (AVGO.O) sa...</td>\n",
       "      <td>(Reuters) - Chipmaker Broadcom Inc (AVGO.O) sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple expands services business to markets in ...</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSL1N2C900N</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>(Reuters) - Apple Inc (AAPL.O) on Tuesday said...</td>\n",
       "      <td>(Reuters) - Apple Inc (AAPL.O) on Tuesday said...</td>\n",
       "      <td>(Reuters) - Apple Inc (AAPL.O) on Tuesday said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Factbox: How to watch Apple TV+, Apple's entry...</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSKBN1XB3TM</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>LOS ANGELES (Reuters) - Apple Inc (AAPL.O) unv...</td>\n",
       "      <td>Here are details on how to subscribe and watch...</td>\n",
       "      <td>LOS ANGELES (Reuters) - Apple Inc (AAPL.O) unv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apple to expand operations in India - IT minister</td>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>https://www.reuters.com/article/idUSL4N2852IX</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NEW DELHI, Nov 25 (Reuters) - India’s informat...</td>\n",
       "      <td>NEW DELHI, Nov 25 (Reuters) - India’s informat...</td>\n",
       "      <td>NEW DELHI, Nov 25 (Reuters) - India’s informat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        date       query  \\\n",
       "0  BRIEF-Apple Inc Says Not Allowing Entertainmen...  2020-03-15  Apple Inc.   \n",
       "1  Apple signs multi-year deals with major music ...  2020-03-12  Apple Inc.   \n",
       "2  Apple signs multi-year deals with major music ...  2020-03-12  Apple Inc.   \n",
       "3  Chinese regulators remove 'Plague Inc' game fr...  2020-02-28  Apple Inc.   \n",
       "4  UPDATE 1-Chinese regulators remove 'Plague Inc...  2020-02-28  Apple Inc.   \n",
       "5                     Apple launches new MacBook Pro  2020-05-04  Apple Inc.   \n",
       "6    Broadcom to supply wireless components to Apple  2020-01-23  Apple Inc.   \n",
       "7  Apple expands services business to markets in ...  2020-04-21  Apple Inc.   \n",
       "8  Factbox: How to watch Apple TV+, Apple's entry...  2019-11-01  Apple Inc.   \n",
       "9  Apple to expand operations in India - IT minister  2019-11-25  Apple Inc.   \n",
       "\n",
       "                                             url ticker  \\\n",
       "0  https://www.reuters.com/article/idUSFWN2B61K2   AAPL   \n",
       "1  https://www.reuters.com/article/idUSKBN20Z33J   AAPL   \n",
       "2  https://www.reuters.com/article/idUSL4N2B54T2   AAPL   \n",
       "3  https://www.reuters.com/article/idUSKCN20M043   AAPL   \n",
       "4  https://www.reuters.com/article/idUSL3N2AS0OO   AAPL   \n",
       "5  https://www.reuters.com/article/idUSL4N2CM29Z   AAPL   \n",
       "6  https://www.reuters.com/article/idUSKBN1ZM32H   AAPL   \n",
       "7  https://www.reuters.com/article/idUSL1N2C900N   AAPL   \n",
       "8  https://www.reuters.com/article/idUSKBN1XB3TM   AAPL   \n",
       "9  https://www.reuters.com/article/idUSL4N2852IX   AAPL   \n",
       "\n",
       "                                             content  \\\n",
       "0  March 14 (Reuters) - Apple Inc: * APPLE INC SA...   \n",
       "1  (Reuters) - Apple Inc has sealed multi-year li...   \n",
       "2  (Reuters) - Apple Inc has sealed multi-year li...   \n",
       "3  BEIJING/SHANGHAI (Reuters) - The video game “P...   \n",
       "4  BEIJING/SHANGHAI (Reuters) - The video game “P...   \n",
       "5  May 4 (Reuters) - Apple Inc on Monday launched...   \n",
       "6  (Reuters) - Chipmaker Broadcom Inc (AVGO.O) sa...   \n",
       "7  (Reuters) - Apple Inc (AAPL.O) on Tuesday said...   \n",
       "8  LOS ANGELES (Reuters) - Apple Inc (AAPL.O) unv...   \n",
       "9  NEW DELHI, Nov 25 (Reuters) - India’s informat...   \n",
       "\n",
       "                                          ps_content  \\\n",
       "0  * APPLE INC SAYS NOT ALLOWING ENTERTAINMENT OR...   \n",
       "1  (Reuters) - Apple Inc has sealed multi-year li...   \n",
       "2  (Reuters) - Apple Inc has sealed multi-year li...   \n",
       "3  The regulator did not respond to Reuters phone...   \n",
       "4  The regulator did not respond to Reuters phone...   \n",
       "5  Apple said here its new lineup of MacBook Pro ...   \n",
       "6  (Reuters) - Chipmaker Broadcom Inc (AVGO.O) sa...   \n",
       "7  (Reuters) - Apple Inc (AAPL.O) on Tuesday said...   \n",
       "8  Here are details on how to subscribe and watch...   \n",
       "9  NEW DELHI, Nov 25 (Reuters) - India’s informat...   \n",
       "\n",
       "                                          bs_content  \n",
       "0  March 14 (Reuters) - Apple Inc: * APPLE INC SA...  \n",
       "1  (Reuters) - Apple Inc has sealed multi-year li...  \n",
       "2  (Reuters) - Apple Inc has sealed multi-year li...  \n",
       "3  BEIJING/SHANGHAI (Reuters) - The video game “P...  \n",
       "4  BEIJING/SHANGHAI (Reuters) - The video game “P...  \n",
       "5  May 4 (Reuters) - Apple Inc on Monday launched...  \n",
       "6  (Reuters) - Chipmaker Broadcom Inc (AVGO.O) sa...  \n",
       "7  (Reuters) - Apple Inc (AAPL.O) on Tuesday said...  \n",
       "8  LOS ANGELES (Reuters) - Apple Inc (AAPL.O) unv...  \n",
       "9  NEW DELHI, Nov 25 (Reuters) - India’s informat...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
