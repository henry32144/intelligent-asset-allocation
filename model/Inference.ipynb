{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0729 18:49:43.043088 17656 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "I0729 18:49:52.989889 17656 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n",
      "I0729 18:49:52.990919 17656 configuration_utils.py:321] Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0729 18:49:54.424886 17656 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "import config\n",
    "import math\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import (accuracy_score, roc_curve, auc)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0729 18:49:57.342915 17656 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n",
      "I0729 18:49:57.343915 17656 configuration_utils.py:321] Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0729 18:49:58.721887 17656 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/distilbert-base-uncased-pytorch_model.bin from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ReutersClassifier(\n",
       "  (distilbert_layer): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cnn_max_pool): CnnMaxPooling(\n",
       "    (cnn): Conv2d(1, 64, kernel_size=(3, 10), stride=(1, 1))\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_portfolio import ReutersClassifier\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ReutersClassifier(n_classes=2, top_k=10, p=0.1, window_size=3, out_channels=64)\n",
    "model.load_state_dict(torch.load(\"../weights/2020-07-29_cnn_distilbert.bin\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2016, 1, 4), datetime.date(2016, 12, 30))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data = joblib.load(\"../data/valid_top10_v2.bin\")\n",
    "valid_data.index.min(), valid_data.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-03 2020-07-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 1 News</th>\n",
       "      <th>Top 2 News</th>\n",
       "      <th>Top 3 News</th>\n",
       "      <th>Top 4 News</th>\n",
       "      <th>Top 5 News</th>\n",
       "      <th>Top 6 News</th>\n",
       "      <th>Top 7 News</th>\n",
       "      <th>Top 8 News</th>\n",
       "      <th>Top 9 News</th>\n",
       "      <th>Top 10 News</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>apple confirms $1 bln investment in softbank t...</td>\n",
       "      <td>update 2-apple confirms $1 bln investment in s...</td>\n",
       "      <td>apple confirms $1 billion investment in softba...</td>\n",
       "      <td>apple pulls new york times app from itunes sto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.11</td>\n",
       "      <td>110.73</td>\n",
       "      <td>110.01</td>\n",
       "      <td>110.27</td>\n",
       "      <td>21118100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>brief-apple says app store generated over $20 ...</td>\n",
       "      <td>update 1-apple is app store generated $20 bln ...</td>\n",
       "      <td>apple is app store generated $20 billion for d...</td>\n",
       "      <td>rpt-update 3-apple pulls new york times apps i...</td>\n",
       "      <td>update 3-apple pulls new york times apps in ch...</td>\n",
       "      <td>apple pulls new york times apps in china after...</td>\n",
       "      <td>india reluctant to give special tax incentives...</td>\n",
       "      <td>apple plans first retail store in s.korea, pos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.17</td>\n",
       "      <td>111.07</td>\n",
       "      <td>110.07</td>\n",
       "      <td>110.83</td>\n",
       "      <td>22193600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>brief-apple inc is ceo tim cook is total 2016 ...</td>\n",
       "      <td>canada is competition watchdog closes two-year...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.99</td>\n",
       "      <td>112.30</td>\n",
       "      <td>110.70</td>\n",
       "      <td>112.07</td>\n",
       "      <td>31751900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>china is wechat seeks slice of apple is app st...</td>\n",
       "      <td>china is wechat seeks slice of apple is app st...</td>\n",
       "      <td>tesla taps apple engineer for autopilot software</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.88</td>\n",
       "      <td>113.46</td>\n",
       "      <td>112.44</td>\n",
       "      <td>113.21</td>\n",
       "      <td>24462100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12</th>\n",
       "      <td>u.s. appeals court revives antitrust lawsuit a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.01</td>\n",
       "      <td>113.39</td>\n",
       "      <td>112.35</td>\n",
       "      <td>113.34</td>\n",
       "      <td>27086200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Top 1 News  \\\n",
       "date                                                            \n",
       "2017-01-04  apple confirms $1 bln investment in softbank t...   \n",
       "2017-01-05  brief-apple says app store generated over $20 ...   \n",
       "2017-01-06  brief-apple inc is ceo tim cook is total 2016 ...   \n",
       "2017-01-10  china is wechat seeks slice of apple is app st...   \n",
       "2017-01-12  u.s. appeals court revives antitrust lawsuit a...   \n",
       "\n",
       "                                                   Top 2 News  \\\n",
       "date                                                            \n",
       "2017-01-04  update 2-apple confirms $1 bln investment in s...   \n",
       "2017-01-05  update 1-apple is app store generated $20 bln ...   \n",
       "2017-01-06  canada is competition watchdog closes two-year...   \n",
       "2017-01-10  china is wechat seeks slice of apple is app st...   \n",
       "2017-01-12                                                NaN   \n",
       "\n",
       "                                                   Top 3 News  \\\n",
       "date                                                            \n",
       "2017-01-04  apple confirms $1 billion investment in softba...   \n",
       "2017-01-05  apple is app store generated $20 billion for d...   \n",
       "2017-01-06                                                NaN   \n",
       "2017-01-10   tesla taps apple engineer for autopilot software   \n",
       "2017-01-12                                                NaN   \n",
       "\n",
       "                                                   Top 4 News  \\\n",
       "date                                                            \n",
       "2017-01-04  apple pulls new york times app from itunes sto...   \n",
       "2017-01-05  rpt-update 3-apple pulls new york times apps i...   \n",
       "2017-01-06                                                NaN   \n",
       "2017-01-10                                                NaN   \n",
       "2017-01-12                                                NaN   \n",
       "\n",
       "                                                   Top 5 News  \\\n",
       "date                                                            \n",
       "2017-01-04                                                NaN   \n",
       "2017-01-05  update 3-apple pulls new york times apps in ch...   \n",
       "2017-01-06                                                NaN   \n",
       "2017-01-10                                                NaN   \n",
       "2017-01-12                                                NaN   \n",
       "\n",
       "                                                   Top 6 News  \\\n",
       "date                                                            \n",
       "2017-01-04                                                NaN   \n",
       "2017-01-05  apple pulls new york times apps in china after...   \n",
       "2017-01-06                                                NaN   \n",
       "2017-01-10                                                NaN   \n",
       "2017-01-12                                                NaN   \n",
       "\n",
       "                                                   Top 7 News  \\\n",
       "date                                                            \n",
       "2017-01-04                                                NaN   \n",
       "2017-01-05  india reluctant to give special tax incentives...   \n",
       "2017-01-06                                                NaN   \n",
       "2017-01-10                                                NaN   \n",
       "2017-01-12                                                NaN   \n",
       "\n",
       "                                                   Top 8 News Top 9 News  \\\n",
       "date                                                                       \n",
       "2017-01-04                                                NaN        NaN   \n",
       "2017-01-05  apple plans first retail store in s.korea, pos...        NaN   \n",
       "2017-01-06                                                NaN        NaN   \n",
       "2017-01-10                                                NaN        NaN   \n",
       "2017-01-12                                                NaN        NaN   \n",
       "\n",
       "           Top 10 News    Open    High     Low   Close      Volume  Dividends  \\\n",
       "date                                                                            \n",
       "2017-01-04         NaN  110.11  110.73  110.01  110.27  21118100.0        0.0   \n",
       "2017-01-05         NaN  110.17  111.07  110.07  110.83  22193600.0        0.0   \n",
       "2017-01-06         NaN  110.99  112.30  110.70  112.07  31751900.0        0.0   \n",
       "2017-01-10         NaN  112.88  113.46  112.44  113.21  24462100.0        0.0   \n",
       "2017-01-12         NaN  113.01  113.39  112.35  113.34  27086200.0        0.0   \n",
       "\n",
       "            Stock Splits ticker  label  \n",
       "date                                    \n",
       "2017-01-04           0.0   AAPL      0  \n",
       "2017-01-05           0.0   AAPL      1  \n",
       "2017-01-06           0.0   AAPL      1  \n",
       "2017-01-10           0.0   AAPL      1  \n",
       "2017-01-12           0.0   AAPL      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = joblib.load(\"../data/test_top10_v2.bin\")\n",
    "print(test_data.index.min(), test_data.index.max())\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "len(dict(Counter(test_data.ticker)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0729 18:50:46.039817 17656 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n",
      "I0729 18:50:46.042818 17656 configuration_utils.py:321] Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0729 18:50:48.697847 17656 tokenization_utils.py:1015] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\YangWang/.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[############################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "from deep_portfolio import progressbar\n",
    "from deep_portfolio import create_dataloader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "test_dataloader = create_dataloader(test_data, tokenizer, 32, 10, 16, shuffle=False)\n",
    "model = model.eval()\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for data in progressbar(test_dataloader):\n",
    "        for d in data[\"ids_and_mask\"]:\n",
    "            d[\"input_ids\"] = d[\"input_ids\"].to(device)\n",
    "            d[\"attention_mask\"] = d[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(data[\"ids_and_mask\"])\n",
    "        outputs = F.softmax(outputs)\n",
    "        pred_list.extend(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_cpu = [pred.to(\"cpu\").tolist() for pred in pred_list]\n",
    "pred_list_final = [pred[1] for pred in pred_list_cpu]\n",
    "pred_list_final = [pred for pred in pred_list_final]\n",
    "test_data[\"pred\"] = pred_list_final\n",
    "final_df = test_data[[\"ticker\", \"pred\"]]\n",
    "final_df.reset_index(drop=False, inplace=True)\n",
    "final_df[\"date\"] = final_df[\"date\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame()\n",
    "for ticker in list(set(final_df.ticker)):\n",
    "    index = pd.date_range(start=\"2017-01-01\", end=\"2020-06-30\", freq='D')\n",
    "    columns = [\"ticker\", \"pred\"]\n",
    "    df = pd.DataFrame(index=index, columns=columns)\n",
    "    df = df.reset_index(drop=False)\n",
    "    df.columns = [\"date\", \"ticker\", \"pred\"]\n",
    "    df[\"date\"] = df[\"date\"].apply(str)\n",
    "    \n",
    "    df_temp = pd.merge(df, final_df[final_df[\"ticker\"] == ticker], on=\"date\")\n",
    "    df_total = pd.concat([df_total, df_temp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker_x</th>\n",
       "      <th>pred_x</th>\n",
       "      <th>ticker_y</th>\n",
       "      <th>pred_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, ticker_x, pred_x, ticker_y, pred_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18937</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>NOW</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18938</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>NOW</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18939</th>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>NOW</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18940</th>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>NOW</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18941</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>NOW</td>\n",
       "      <td>0.529238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18942 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date ticker      pred\n",
       "0      2017-01-04   AAPL  0.529238\n",
       "1      2017-01-05   AAPL  0.529238\n",
       "2      2017-01-06   AAPL  0.529238\n",
       "3      2017-01-10   AAPL  0.529238\n",
       "4      2017-01-12   AAPL  0.529238\n",
       "...           ...    ...       ...\n",
       "18937  2020-03-17    NOW  0.529238\n",
       "18938  2020-04-21    NOW  0.529238\n",
       "18939  2020-04-30    NOW  0.529238\n",
       "18940  2020-05-05    NOW  0.529238\n",
       "18941  2020-06-26    NOW  0.529238\n",
       "\n",
       "[18942 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.groupby(\"ticker\").agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107481"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1277*99 - 18942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191.33333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18942/99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
