{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=['''watching time chasers it obvious that it was made by a bunch of friends maybe they were sitting around one day in film \n",
    "       school and said hey lets pool our money together and make a really bad movie! or something like that what ever they said \n",
    "       they still ended up making a really bad movie--dull story bad script lame acting poor cinematography bottom of the barrel \n",
    "       stock music etc all corners were cut except the one that would have prevented this films release lifes like that''',\n",
    "       '''i saw this film about 20 years ago and remember it as being particularly nasty i believe it is based on a true incident:\n",
    "       a young man breaks into a nurses home and rapes tortures and kills various womenit is in black and white but saves the \n",
    "       colour for one shocking shotat the end the film seems to be trying to make some political statement but it just comes \n",
    "       across as confused and obsceneavoid''',\n",
    "       '''minor spoilersin new york joan barnard elvire audrey is informed that her husband the archeologist arthur barnard john \n",
    "       saxon was mysteriously murdered in italy while searching an etruscan tomb joan decides to travel to italy in the company \n",
    "       of her colleague who offers his support once in italy she starts having visions relative to an ancient people and maggots\n",
    "       many maggots after shootings and weird events joan realizes that her father is an international drug dealer there are \n",
    "       drugs hidden in the tomb and her colleague is a detective of the narcotic department the story ends back in new york \n",
    "       when joan and her colleague decide to get married with each other in a very romantic end yesterday i had the displeasure \n",
    "       of wasting my time watching this crap the story is so absurd mixing thriller crime supernatural and horror and even a \n",
    "       romantic end in a non-sense way the acting is the worst possible highlighting the horrible performance of the beautiful \n",
    "       elvire audrey john saxon just gives his name to the credits and works less than five minutes when his character is \n",
    "       killed the special effects are limited to maggots everywhere the direction is ridiculous i lost a couple of hours of my \n",
    "       life watching assassinio al cimitero etrusco if you have the desire or curiosity of seeing this trash choose another \n",
    "       movie go to a pizzeria watch tv go sleep navigate in internet go to the gym but do not waste your time like i did my \n",
    "       vote is twotitle brazil: o mistÃ©rio etrusco the etruscan mystery''',\n",
    "       '''i went to see this film with a great deal of excitement as i was at school with the director he was even a good friend \n",
    "       of mine for a while but sorry mate this film stinksi can only talk about what was wrong with the first half because \n",
    "       thats when i walked out and went to the pub for a much needed drink:1 someones standing on a balcony about to jump and \n",
    "       so you send a helicopter to shine a searchlight on them i dont think so - nothing would make them more likely to jump2 \n",
    "       local radio doesnt send reporters to cover people about to attempt suicide - again for fear of pressuring them into \n",
    "       jumping - or for fear of encouraging copy-cat instances3 whatever the circumstances radio reporters dont do live \n",
    "       broadcasts from the 10th floor of a tower block radio cars dont carry leads long enough to connect the microphone and \n",
    "       headphones to the transmitter4 the stuck in the lift scene was utterly derivative5 the acting and direction was almost \n",
    "       non existenti could go on but i wont''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\YangWang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from typing import List\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def print_dict(in_dict, partial=True):\n",
    "    i=0\n",
    "    for k, v in in_dict.items():\n",
    "        print(\"{:10}: {:4f}\".format(k, v))\n",
    "        i += 1\n",
    "        if partial and i>20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(document: str, corpus: dict =None):\n",
    "    \"\"\"\n",
    "    Counts the term frequency for a given Document string.\n",
    "    Instructions are given for computing `Normalized Term frequency`.\n",
    "    \n",
    "    \n",
    "    Inputs:\n",
    "        document: str\n",
    "        \n",
    "    Returns:\n",
    "        tf: A dict, where tf[term] = frequency(term, doc_idx)\n",
    "    \"\"\"\n",
    "\n",
    "    #### Your code starts here ####\n",
    "    TF_dict = {}\n",
    "    document = word_tokenize(document)\n",
    "    for word in document:\n",
    "        if word in TF_dict:\n",
    "            TF_dict[word] += 1\n",
    "        else:\n",
    "            TF_dict[word] = 1\n",
    "    # Computes tf for each word\n",
    "    for word in TF_dict:\n",
    "        TF_dict[word] = TF_dict[word] / len(document)\n",
    "    ###^^ Your code ends here ^^###\n",
    "\n",
    "    return TF_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watching  : 0.011236\n",
      "time      : 0.011236\n",
      "chasers   : 0.011236\n",
      "it        : 0.022472\n",
      "obvious   : 0.011236\n",
      "that      : 0.044944\n",
      "was       : 0.011236\n",
      "made      : 0.011236\n",
      "by        : 0.011236\n",
      "a         : 0.033708\n",
      "bunch     : 0.011236\n",
      "of        : 0.022472\n",
      "friends   : 0.011236\n",
      "maybe     : 0.011236\n",
      "they      : 0.033708\n",
      "were      : 0.022472\n",
      "sitting   : 0.011236\n",
      "around    : 0.011236\n",
      "one       : 0.022472\n",
      "day       : 0.011236\n",
      "in        : 0.011236\n"
     ]
    }
   ],
   "source": [
    "tf_all = [term_frequency(doc) for doc in sentences]\n",
    "print_dict(tf_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_count_dict(tf_dict):\n",
    "    \"\"\" Returns a dictionary whose keys are all the unique words in\n",
    "    the dataset and whose values count the number of reviews in which\n",
    "    the word appears.\n",
    "    \"\"\"\n",
    "    count_dict = {}\n",
    "    # Run through each review's tf dictionary and increment countDict's (word, doc) pair\n",
    "    for review in tf_dict:\n",
    "        for word in review:\n",
    "            if word in count_dict:\n",
    "                count_dict[word] += 1\n",
    "            else:\n",
    "                count_dict[word] = 1\n",
    "    return count_dict\n",
    "\n",
    "#Stores the review count dictionary\n",
    "count_dict = compute_count_dict(tf_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_idf(corpus_cross_doc: set,\n",
    "              tf_all_docs: List[dict], \n",
    "              number_of_docs: int):\n",
    "    \"\"\"\n",
    "    Counts the idf for a given corpus, keys from tf_all_docs, Document numbers.\n",
    "    \n",
    "    \n",
    "    Inputs:\n",
    "        corpus_cross_doc: set,\n",
    "        tf_all_docs: List[dict], \n",
    "        number_of_docs: int\n",
    "        \n",
    "    Returns:\n",
    "        idf: A dict, idf weights\n",
    "    \"\"\"\n",
    "\n",
    "    #### Your code starts here ####\n",
    "    idf = dict.fromkeys(tf_all_docs.keys(), 0)\n",
    "    for word, val in idf.items():\n",
    "        idf[word] = math.log10(number_of_docs / (float(val) + 1))\n",
    "    \n",
    "    ###^^ Your code ends here ^^###\n",
    "\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 7; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-4e97f444627b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_copus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0midf_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_idf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-45301a67feee>\u001b[0m in \u001b[0;36mcount_idf\u001b[1;34m(corpus_cross_doc, tf_all_docs, number_of_docs)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#### Your code starts here ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0midf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_cross_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0midf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_docs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dictionary update sequence element #0 has length 7; 2 is required"
     ]
    }
   ],
   "source": [
    "D = len(sentences)\n",
    "all_copus = []\n",
    "\n",
    "for doc in sentences:\n",
    "    all_copus += word_tokenize(doc)\n",
    "\n",
    "corpus = set(all_copus)\n",
    "\n",
    "idf_weights = count_idf(corpus, tf_all, D)\n",
    "print_dict(idf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
