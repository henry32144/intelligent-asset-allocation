{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import *\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reuters_Crawler:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        query: str\n",
    "        \n",
    "    Example:\n",
    "        RC = Reuters_Crawler()\n",
    "        df = RC.parse_to_dataframe()\n",
    "    \"\"\"\n",
    "    def __init__(self, query=\"google\"):\n",
    "        self.query = query\n",
    "        self.url = \"https://www.reuters.com/search/news?blob={}&sortBy=date&dateRange=all\".format(query)\n",
    "        self.driver_path = r\"./chromedriver.exe\"\n",
    "        self.driver = webdriver.Chrome(self.driver_path)\n",
    "        self.next_button = '//*[@id=\"content\"]/section[2]/div/div[1]/div[4]/div/div[4]/div[1]'\n",
    "    \n",
    "    def parse_to_dataframe(self, parse_time=10):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            parse_time: int (seconds)\n",
    "        \"\"\"\n",
    "        # Open driver\n",
    "        self.driver.get(self.url)\n",
    "        time.sleep(2)\n",
    "        # Scroll down page\n",
    "        start_time = time.time()\n",
    "        while (int(time.time() - start_time) < parse_time):\n",
    "            if self.check_exists_by_xpath(self.next_button): \n",
    "                self.driver.find_element_by_xpath(self.next_button).click()\n",
    "                time.sleep(2 + random.random())\n",
    "            else: \n",
    "                break\n",
    "        # Parsing\n",
    "        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        self.driver.quit()\n",
    "        news_list = soup.find_all(name=\"div\", attrs={\"class\": \"search-result-content\"})\n",
    "        news_list_generator = self.get_news_list(news_list)\n",
    "        df = pd.DataFrame(list(news_list_generator), columns=[\"title\", \"date\", \"query\", \"url\"])\n",
    "        return df\n",
    "        \n",
    "                \n",
    "    def check_exists_by_xpath(self, xpath):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath(xpath)\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_news_list(self, news_list):\n",
    "        for i in range(len(news_list)):\n",
    "            title = news_list[i].find(name=\"a\").text\n",
    "            date = news_list[i].find(name=\"h5\", attrs={\"class\": \"search-result-timestamp\"}).text\n",
    "            date = parser.parse(date, tzinfos={\"EDT\": \"UTC-8\"})\n",
    "            url = news_list[i].find(name=\"a\").get(\"href\")\n",
    "            url = \"https://www.reuters.com\" + url\n",
    "            yield [title, date, self.query, url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC = Reuters_Crawler()\n",
    "df = RC.parse_to_dataframe(parse_time=60*60)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(df, \"./reuters_news_v1.joblib\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
